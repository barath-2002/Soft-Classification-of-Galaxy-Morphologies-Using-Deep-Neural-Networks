{"cells":[{"cell_type":"markdown","metadata":{},"source":["## ST456 Deep Learning Project"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T12:03:44.815209Z","iopub.status.busy":"2024-04-06T12:03:44.814791Z","iopub.status.idle":"2024-04-06T12:03:45.232712Z","shell.execute_reply":"2024-04-06T12:03:45.231533Z","shell.execute_reply.started":"2024-04-06T12:03:44.815180Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import os\n","import gc\n","import random\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import zipfile\n","import keras\n","from sklearn.model_selection import train_test_split\n","from keras import layers\n","\n","#from keras import ops\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalMaxPooling2D\n","from keras.preprocessing import image\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from keras.optimizers import Adam\n","from keras.metrics import MeanSquaredError, RootMeanSquaredError\n","from keras.utils import to_categorical\n","from keras import backend as K\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","print(tf.config.list_physical_devices('GPU'))"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T11:57:13.134792Z","iopub.status.busy":"2024-04-06T11:57:13.134024Z","iopub.status.idle":"2024-04-06T11:57:13.141070Z","shell.execute_reply":"2024-04-06T11:57:13.139728Z","shell.execute_reply.started":"2024-04-06T11:57:13.134757Z"},"trusted":true},"outputs":[],"source":["data_path = '/kaggle/input/processed-galaxy-data/compressed_img_target.npz'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T11:57:13.143175Z","iopub.status.busy":"2024-04-06T11:57:13.142739Z","iopub.status.idle":"2024-04-06T11:57:24.235723Z","shell.execute_reply":"2024-04-06T11:57:24.233746Z","shell.execute_reply.started":"2024-04-06T11:57:13.143142Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(61578, 64, 64, 3)\n"]}],"source":["# load cropped, compressed images\n","loaded_arrays = np.load(data_path)\n","\n","data = loaded_arrays['images']\n","target = loaded_arrays['target']\n","\n","batch_size = 32 * 2  # 2 GPUs\n","\n","print(data.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T12:03:06.443374Z","iopub.status.busy":"2024-04-06T12:03:06.442885Z","iopub.status.idle":"2024-04-06T12:03:06.453726Z","shell.execute_reply":"2024-04-06T12:03:06.452464Z","shell.execute_reply.started":"2024-04-06T12:03:06.443335Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(37,)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["prob_means= np.mean(target, axis=0)\n","prob_means.shape"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T11:57:24.252930Z","iopub.status.busy":"2024-04-06T11:57:24.252317Z","iopub.status.idle":"2024-04-06T11:57:24.284731Z","shell.execute_reply":"2024-04-06T11:57:24.282504Z","shell.execute_reply.started":"2024-04-06T11:57:24.252882Z"},"trusted":true},"outputs":[],"source":["# Define RMSE loss function\n","def rmse_custom(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T23:57:40.753008Z","iopub.status.busy":"2024-04-02T23:57:40.752428Z","iopub.status.idle":"2024-04-02T23:57:42.186591Z","shell.execute_reply":"2024-04-02T23:57:42.185804Z","shell.execute_reply.started":"2024-04-02T23:57:40.752976Z"},"trusted":true},"outputs":[],"source":["# train/validation/test split due to data augmentation\n","# 72% train, 8% validation, 20% test\n","X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state = 42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n","\n","# Normalize pixel values to range [0, 1]\n","X_train = X_train.astype('float32') / 255\n","X_test = X_test.astype('float32') / 255\n","X_val = X_val.astype('float32') / 255\n","\n","y_train = y_train.astype('float32')\n","y_test = y_test.astype('float32')\n","y_val = y_val.astype('float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T23:57:42.195849Z","iopub.status.busy":"2024-04-02T23:57:42.195574Z","iopub.status.idle":"2024-04-02T23:57:42.205952Z","shell.execute_reply":"2024-04-02T23:57:42.205138Z","shell.execute_reply.started":"2024-04-02T23:57:42.195821Z"},"trusted":true},"outputs":[],"source":["data_augmentation = ImageDataGenerator(\n","    rotation_range=360,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","train_datagen = data_augmentation.flow(X_train, y_train, batch_size=batch_size)\n","validation_datagen = ImageDataGenerator().flow(X_val, y_val, batch_size=batch_size)\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Recording the effects of constraint coefficient on performance of simple CNN\n","\n","As we increase the force of the decision tree constraints on the customised loss function, how does this impact model performance?"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-03T14:12:15.601625Z","iopub.status.busy":"2024-04-03T14:12:15.601078Z","iopub.status.idle":"2024-04-03T14:12:15.620072Z","shell.execute_reply":"2024-04-03T14:12:15.619139Z","shell.execute_reply.started":"2024-04-03T14:12:15.601599Z"},"trusted":true},"outputs":[],"source":["# these regularization parameters correspond to the galaxy-zoo decision tree structure\n","def custom_loss(y_true, y_pred, l=0.001):\n","    c1 = tf.abs(tf.reduce_sum(y_pred[:, 0:3], axis=1) - 1) # Class 1 constraint\n","    c2 = tf.abs(tf.reduce_sum(y_pred[:, 13:15], axis=1) - 1) # Class 6 constraint\n","    c3 = tf.abs((y_pred[:, 3] + y_pred[:, 4]) - y_pred[:, 1]) # Class 2 constraint\n","    c4 = tf.abs((y_pred[:, 15] + y_pred[:, 16] + y_pred[:, 17]) - y_pred[:, 10]) # Class 7 constraint\n","    c5 = tf.abs(tf.reduce_sum(y_pred[:, 18:25], axis=1) - y_pred[:, 13]) # Class 8 constraint\n","    c6 = tf.abs(tf.reduce_sum(y_pred[:, 25:28], axis=1) - y_pred[:, 3]) # Class 9 constraint\n","    c7 = tf.abs(tf.reduce_sum(y_pred[:, 5:7], axis=1) - y_pred[:, 4]) # Class 3 constraint\n","    c8 = tf.abs(tf.reduce_sum(y_pred[:, 7:9], axis=1) - y_pred[:, 4]) # Class 4 constraint\n","    c9 = tf.abs(tf.reduce_sum(y_pred[:, 28:31], axis=1) - y_pred[:, 7]) # Class 10 constraint\n","    c10 = tf.abs(tf.reduce_sum(y_pred[:, 9:13], axis=1) - y_pred[:, 7] - y_pred[:, 8]) # Class 5 constraint\n","    c11 = tf.abs(tf.reduce_sum(y_pred[:, 31:37], axis=1) - y_pred[:, 7]) # Class 11 constraint\n","    \n","    # l (lambda) coefficient controls the force of penalties\n","    c_loss = l*(c1+c2+c3+c4+c5+c6+c7+c8+c9+c10+c11)\n","\n","    # base loss (mean squared error)\n","    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n","\n","    # combine base loss with constraints\n","    return mse_loss + c_loss\n","\n","def custom_loss_wrapper(l=0.001):\n","    def loss(y_true, y_pred):\n","        return custom_loss(y_true, y_pred, l=l)\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T23:57:42.224130Z","iopub.status.busy":"2024-04-02T23:57:42.223849Z","iopub.status.idle":"2024-04-02T23:57:42.239759Z","shell.execute_reply":"2024-04-02T23:57:42.238796Z","shell.execute_reply.started":"2024-04-02T23:57:42.224107Z"},"trusted":true},"outputs":[],"source":["# Build simple CNN\n","# to use two GPUs in parallel\n","strategy = tf.distribute.MirroredStrategy()\n","print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T19:22:23.964052Z","iopub.status.busy":"2024-04-02T19:22:23.963642Z","iopub.status.idle":"2024-04-02T19:31:14.632359Z","shell.execute_reply":"2024-04-02T19:31:14.630958Z","shell.execute_reply.started":"2024-04-02T19:22:23.964018Z"},"trusted":true},"outputs":[],"source":["l = [0.001, 0.01, 0.1, 0.2, 0.5, 1]\n","num_epochs = 30\n","results = {'lambda':[], 'rmse':[]}\n","\n","# so we can keep resetting the weights\n","\n","fig, axes = plt.subplots(3, 2, figsize=(12, 8), sharex='col', sharey='row')\n","axes = axes.flatten()\n","\n","# Loop through lambda values\n","for i, lamda in enumerate(l):\n","    print(f'Training Lambda = {lamda}')\n","    print('-'*200)\n","    \n","    with strategy.scope():\n","        model = Sequential()\n","        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n","        model.add(MaxPooling2D((2, 2)))\n","        model.add(Conv2D(64, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D((2, 2)))\n","        model.add(Conv2D(128, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D((2, 2)))\n","        model.add(Conv2D(128, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D((2, 2)))\n","        model.add(Flatten())\n","        model.add(Dense(512, activation='relu'))\n","        model.add(Dense(37, activation='sigmoid'))\n","\n","        model.compile(optimizer='adam', loss=custom_loss_wrapper(l=lamda), metrics=[RootMeanSquaredError()])\n","\n","        # Train the model\n","        history = model.fit(\n","            train_datagen,\n","            steps_per_epoch=len(X_train) // 32,\n","            epochs=num_epochs,\n","            validation_data=validation_datagen,\n","            validation_steps=len(X_val) // 32\n","        )\n","    \n","    # Visualize loss and metric by training epoch\n","    train_metric = history.history['root_mean_squared_error']\n","    val_metric = history.history['val_root_mean_squared_error']\n","    epochs = range(1, len(train_metric) + 1)\n","    \n","    # Plot training and validation metric\n","    axes[i].plot(epochs, train_metric, marker='o', color='b', label='Training RMSE')\n","    axes[i].plot(epochs, val_metric, marker='o', color='r', label='Validation RMSE')\n","    axes[i].set_title(f'$\\lambda={lamda}$') \n","    axes[i].set_xlabel('Epochs') \n","    axes[i].set_ylabel('RMSE')\n","    plt.tight_layout()\n","    \n","    # Save plot\n","    plt.savefig(f'plot_l_{lamda}.png')\n","    \n","    # Save model\n","    model_path = f'base_model_lambda_{lamda}.keras'\n","    model.save(model_path)\n","    \n","    # Evaluate model on test data\n","    test_loss, test_rmse = model.evaluate(X_test, y_test)\n","    \n","    # Store results\n","    results['rmse'].append(test_rmse)\n","    results['lambda'].append(lamda)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_df = pd.DataFrame(results)\n","results_df.to_csv('reg_effect.csv', index=False)\n","results_df.head()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4687299,"sourceId":7966698,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
